---
title: "fuseMLR"
author: Cesaire J. K. Fouodo
output: 
  md_document:
    variant: gfm
    preserve_yaml: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!-- badges: start -->
[![R-CMD-check](https://github.com/imbs-hl/fuseMLR/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/imbs-hl/fuseMLR/actions/workflows/R-CMD-check.yaml)
[![codecov](https://codecov.io/github/imbs-hl/fuseMLR/graph/badge.svg?token=SZU7NGK8G8)](https://codecov.io/github/imbs-hl/fuseMLR)
[![Lifecycle: Maturing](https://img.shields.io/badge/lifecycle-Maturing-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#Maturing)
[![CRAN downloads](http://www.r-pkg.org/badges/version/fuseMLR)](http://cranlogs.r-pkg.org/badges/grand-total/fuseMLR)
[![Stack Overflow](https://img.shields.io/badge/stackoverflow-questions-orange.svg)](https://stackoverflow.com/questions/tagged/fuseMLR)
<!-- badges: end -->

### fuseMLR
Cesaire J. K. Fouodo

### Introduction
Recent technological advances have enabled the simultaneous collection of multi-omics data, i.e., different types or modalities of molecular data across various organ tissues of patients. For integrative predictive modeling, the analysis of such data is particularly challenging. Ideally, data from the different modalities are measured in the same individuals, allowing for early or intermediate integrative techniques. However, they are often not applicable when patient data only partially overlap, which requires either reducing the datasets or imputing missing values. Additionally, the characteristics of each data modality may necessitate specific statistical methods rather than applying the same method across all modalities. Late integration modeling approaches analyze each data modality separately to obtain modality-specific predictions. These predictions are then integrated to train aggregative models like Lasso, random forests, or compute the weighted mean of modality-specific predictions. 

We introduce the R package fuseMLR for late integration prediction modeling. This comprehensive package enables users to define a training process with multiple data modalities and modality-specific machine learning methods. The package is user-friendly, facilitates variable selection and training of different models across modalities, and automatically performs aggregation once modality-specific training is completed. We simulated multi-omics data to illustrate the usage of our new package for conducting late-stage multi-omics integrative modeling.

`fuseMLR` is an object-oriented package based on `R6` version 2.5.1. Refer to our [cheat sheet](https://github.com/imbs-hl/fuseMLR/blob/master/README_files/figure-gfm/fusemlrcheatsheet.pdf) for a quick overview of classes and functionalities.

### Installation

Install the development version from GitHub with

```R
devtools::install_github("imbs-hl/fuseMLR")
```
### Package overview

The following figure illustrates the general architecture of `fuseMLR`:

```{r, echo=FALSE, out.width="70%", out.height="100%"}
knitr::include_graphics("README_files/figure-gfm/structure.png")
```

The general architecture of `fuseMLR` includes the collection classes `Training`, `TrainLayer`, and `TrainMetaLayer`. `TrainLayer` and `TrainMetaLayer` are stored within a `Training` instance, while `TrainData`, `Lrnr`, and `VarSel` (for variable selection) are stored within a `TrainLayer` or `MetaTrainLayer` instance. An `Training` object can be used to automatically conduct layer-specific variable selection and train layer-specfic and meta models.

### Usage example

The following example is based on simulated data available in `fuseMLR`. Data have been simulated using the R package `InterSIM`, version 2.2.0. 

```{r libraries, warning = FALSE}
library(fuseMLR)
library(UpSetR)
library(ranger)
library(DescTools)
```

#### A) Simulated data.

Two types of data were simulated: training and testing datasets. Each consists of four `data.frame`sâ€”gene expression, protein expression, methylation data, and target variable observations. Individuals are organized in rows, variables in columns, with an additional column for individual IDs. In total, $70$ individuals with $50$ individuals pro layer have been simulated for training, and $23$ ($20$ per layer) for testing. Individuals do not necessarily overlapped. Effects have been introduced for gene expression and methylation by shifting the means by $0.5$ to create case-control study with $50$% prevalence. Individuals do not necessarily overlap. Effects were introduced in gene expression and methylation by shifting the means by 0.5 to create a case-control study. For illustration, the number of variables was kept smaller than what is typically expected in reality. The data simulation code is available [here](https://github.com/imbs-hl/fuseMLR/blob/master/test_code/build_data.R).


```{r data_exam, include=TRUE, eval=TRUE}
data("entities")
# This is a list containing two lists of data: training and test.
# Each sublist contains three entities.
str(object = entities, max.level = 2L)
```

Variable selection, training and prediction are the main functionalities of `fuseMLR`. We can perform variable selection, train and fuse models for training studies, and predict new studies.

#### B) Instantiate training resources

We need to set up training resources.

```{r training, include=TRUE, eval=TRUE}
training <- Training$new(id = "training",
                         ind_col = "IDS",
                         target = "disease",
                         target_df = entities$training$target)
# See also training$summary()
print(training)
```

- Prepare new training layers: Training layers are components of a study and represent the second component of a `fuseMLR` object.

```{r training_layers, include=TRUE, eval=TRUE}
tl_ge <- TrainLayer$new(id = "geneexpr", training = training)
tl_pr <- TrainLayer$new(id = "proteinexpr", training = training)
tl_me <- TrainLayer$new(id = "methylation", training = training)
# We also prepare the meta layer for the meta analysis.
tl_meta <- TrainMetaLayer$new(id = "meta_layer", training = training)
```

- Add training data (entities) to layers: Exclude the meta layer, as it is modified internally after the training phase.

```{r training_data, include=TRUE, eval=TRUE}
train_data_ge <- TrainData$new(id = "geneexpr",
                               train_layer = tl_ge,
                               data_frame = entities$training$geneexpr)
train_data_pr <- TrainData$new(id = "proteinexpr",
                               train_layer = tl_pr,
                               data_frame = entities$training$proteinexpr)
train_data_me <- TrainData$new(id = "methylation",
                               train_layer = tl_me,
                               data_frame = entities$training$methylation)
# An overview of the gene expression training data
print(train_data_ge)
# An overview of the gene expression training layer
print(tl_ge)
# An overview of the training resources
print(training)
```

- An upset plot of the training data: Visualize patient overlap across layers.

```{r upsetplot, include=TRUE, eval=TRUE, }
training$upset(order.by = "freq")
```

#### C) Variable selection

We need to set up variable selection methods to our training resources. Note that this can be the same method or different layer-specific methods. For simplicity, we will set up the same method on all layers.

- Instantiate the variable selection method and assign training layers.

```{r varsel_object, include=TRUE, eval=TRUE}
varsel_ge <- VarSel$new(id = "varsel_geneexpr",
                        package = "Boruta",
                        varsel_fct = "Boruta",
                        varsel_param = list(num.trees = 1000L,
                                            mtry = 3L,
                                            probability = TRUE),
                        train_layer = tl_ge)

varsel_pr <- VarSel$new(id = "varsel_proteinexpr",
                        package = "Boruta",
                        varsel_fct = "Boruta",
                        varsel_param = list(num.trees = 1000L,
                                            mtry = 3L,
                                            probability = TRUE),
                        train_layer = tl_pr)
varsel_me <- VarSel$new(id = "varsel_methylation",
                        package = "Boruta",
                        varsel_fct = "Boruta",
                        varsel_param = list(num.trees = 1000L,
                                            mtry = 3L,
                                            probability = TRUE),
                        train_layer = tl_me)
```

- Perform variable selection on our training resources

```{r varsel, include=TRUE, eval=TRUE}
set.seed(5467)
var_sel_res <- training$varSelection()
print(var_sel_res)
```

For each layer, the variable selection results show the chosen variables. In this example, we perform variable selection. Users can opt to conduct variable selection on individual layers if desired.

#### D) Training

We can now train our models using the subset of selected variables. Users can choose to set up layer-specific learners, but for illustration, we will use the same learner for all layers.

- Set up learners for each layer. We will use a weighted sum, implemented internally by `fuseMLR`, for the meta-analysis.

```{r lrner, include=TRUE, eval=TRUE}
lrner_ge <- Lrner$new(id = "ranger",
                      package = "ranger",
                      lrn_fct = "ranger",
                      param_train_list = list(probability = TRUE,
                                               mtry = 1L),
                      train_layer = tl_ge)
lrner_pr <- Lrner$new(id = "ranger",
                      package = "ranger",
                      lrn_fct = "ranger",
                      param_train_list = list(probability = TRUE,
                                               mtry = 1L),
                      train_layer = tl_pr)
lrner_me <- Lrner$new(id = "ranger",
                      package = "ranger",
                      lrn_fct = "ranger",
                      param_train_list = list(probability = TRUE,
                                               mtry = 1L),
                      train_layer = tl_me)
lrner_meta <- Lrner$new(id = "weighted",
                        lrn_fct = "weightedMeanLearner",
                        param_train_list = list(),
                        na_rm = FALSE,
                        train_layer = tl_meta)
```

- Train the models with the selected variables.

```{r lrner_train, include=TRUE, eval=TRUE}
set.seed(5462)
# Retrieve the target variable for resampling reasons. Resampling will be used by
# fuseMLR to generate meta data.
disease <- training$getTargetValues()$disease
trained <- training$train(resampling_method = "caret::createFolds",
                          resampling_arg = list(y = disease,
                                                k = 10L),
                          use_var_sel = TRUE,
                          verbose = FALSE)
# Let us now check the status of our training resources.
print(trained)
# Let us check the status of a layer as well.
print(tl_ge)

## On the meta model
tmp_model <- tl_meta$getModel()
print(tmp_model$getBaseModel())
```

- Retrieve the basic model of a specific layer.

```{r basic_lrnr, include=TRUE, eval=TRUE}
model_ge <- tl_ge$getModel()
print(model_ge)
```

#### E) Predicting

Now, we have created training resources, performed variable selection and trained the models with the chosen variables. In this section, we create testing resources and make predictions for new data.

- Create the testing object.

```{r testing, include=TRUE, eval=TRUE}
testing <- Testing$new(id = "testing", ind_col = "IDS")
```

- Create new layers.

```{r new_layer, include=TRUE, eval=TRUE}
nl_ge <- TestLayer$new(id = "geneexpr", testing = testing)
nl_pr <- TestLayer$new(id = "proteinexpr", testing = testing)
nl_me <- TestLayer$new(id = "methylation", testing = testing)
```

- Instantiate and add new training data to new layers.

```{r testing_data, include=TRUE, eval=TRUE}
new_data_ge <- TestData$new(id = "geneexpr",
                            new_layer = nl_ge,
                            data_frame = entities$testing$geneexpr)
new_data_pr <- TestData$new(id = "proteinexpr",
                            new_layer = nl_pr,
                            data_frame = entities$testing$proteinexpr)
new_data_me <- TestData$new(id = "methylation",
                            new_layer = nl_me,
                            data_frame = entities$testing$methylation)
```

- An upset plot of the training data: Visualize patient overlap across layers.

```{r upsetplot_new, include=TRUE, eval=TRUE, }
testing$upset(order.by = "freq")
```

- Predict the testing object.

```{r new_pred, include=TRUE, eval=TRUE}
predictions <- training$predict(testing = testing)
print(predictions)
```

- Prediction performances for layer-specific available patients, and all patients on the meta layer.

```{r performance_all, include=TRUE, eval=TRUE}
pred_values <- predictions$predicted_values
actual_pred <- merge(x = pred_values,
                     y = entities$testing$target,
                     by = "IDS",
                     all.y = TRUE)
x <- as.integer(actual_pred$disease == 2L)

# On all patients
perf_estimated <- sapply(X = actual_pred[ , 2L:5L], FUN = function (my_pred) {
  bs <- BrierScore(x = x[complete.cases(my_pred)],
                   pred = my_pred[complete.cases(my_pred)], na.rm = TRUE)
  return(bs)
})
print(perf_estimated)
```

- Prediction performances for overlapping individuals.

```{r performance_overlap, include=TRUE, eval=TRUE}
# On overlapping patients
perf_overlapping <- sapply(X = actual_pred[complete.cases(actual_pred),
                                           2L:5L],
                           FUN = function (my_pred) {
                             bs <- BrierScore(x = x[complete.cases(actual_pred)], pred = my_pred)
                             return(bs)
                           })
print(perf_overlapping)
```

Note that our example is based on simulated data for usage illustration; only one run is not enough to appreciate the performances of our models.

&copy; 2024 Institute of Medical Biometry and Statistics (IMBS). All rights reserved.
